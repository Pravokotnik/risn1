#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from rclpy.qos import qos_profile_sensor_data, QoSReliabilityPolicy

from sensor_msgs.msg import Image, PointCloud2
from sensor_msgs_py import point_cloud2 as pc2

from visualization_msgs.msg import Marker

from cv_bridge import CvBridge, CvBridgeError
import cv2
import numpy as np

from ultralytics import YOLO

from geometry_msgs.msg import PoseWithCovarianceStamped
import math
from collections import defaultdict

class detect_faces(Node):

    def __init__(self):
        super().__init__('detect_faces')

        self.declare_parameters(
            namespace='',
            parameters=[
                ('device', ''),
        ])

        marker_topic = "/people_marker"

        self.detection_color = (0,0,255)
        self.device = self.get_parameter('device').get_parameter_value().string_value

        self.bridge = CvBridge()
        self.scan = None

        self.rgb_image_sub = self.create_subscription(Image, "/oakd/rgb/preview/image_raw", self.rgb_callback, qos_profile_sensor_data)
        self.pointcloud_sub = self.create_subscription(PointCloud2, "/oakd/rgb/preview/depth/points", self.pointcloud_callback, qos_profile_sensor_data)

        self.amcl_pose_sub = self.create_subscription(PoseWithCovarianceStamped, "/amcl_pose", self.amcl_pose_callback, qos_profile_sensor_data)

        self.marker_pub = self.create_publisher(Marker, marker_topic, QoSReliabilityPolicy.BEST_EFFORT)

        self.model = YOLO("yolov8n.pt")

        self.faces = []

        self.robot_position = None
        self.robot_yaw = None

        self.output_file = "faces_pos.txt"

        self.get_logger().info(f"Node has been initialized! Will publish face markers to {marker_topic}.")

    def amcl_pose_callback(self, data):
        self.robot_position = (
            data.pose.pose.position.x,
            data.pose.pose.position.y
        )

        orientation = data.pose.pose.orientation
        self.robot_yaw = self.quaternion_to_yaw(orientation)
    
    def quaternion_to_yaw(self, orientation):
        x = orientation.x
        y = orientation.y
        z = orientation.z
        w = orientation.w

        yaw = np.arctan2(2.0 * (w * z + x * y), 1.0 - 2.0 * (y * y + z * z))
        return yaw
     
    def save_dictionary_to_file(self, face_id, robot_coords, face_coords):
        with open(self.output_file, "a") as f:
            f.write(f"Face ID: {face_id}, Robot Coordinates: {robot_coords}, Face Coordinates: {face_coords}\n")
        self.get_logger().info(f"Appended new entry to {self.output_file}")


    def rgb_callback(self, data):

        self.faces = []

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")

            self.get_logger().info(f"Running inference on image...")

            # CHANGED: Use track instead of predict for persistent IDs
            res = self.model.track(cv_image, imgsz=(256, 320), show=False, verbose=False, 
                                 classes=[0], device=self.device, persist=True)

            # iterate over results
            for x in res:
                bbox = x.boxes.xyxy
                if bbox.nelement() == 0: # skip if empty
                    continue

                # CHANGED: Get tracking ID
                track_id = int(x.boxes.id[0]) if x.boxes.id is not None else 0
                self.get_logger().info(f"Person {track_id} detected!")

                bbox = bbox[0]

                # draw rectangle
                cv_image = cv2.rectangle(cv_image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), self.detection_color, 3)

                cx = int((bbox[0]+bbox[2])/2)
                cy = int((bbox[1]+bbox[3])/2)

                # draw the center of bounding box
                cv_image = cv2.circle(cv_image, (cx,cy), 5, self.detection_color, -1)

                # CHANGED: Store ID with coordinates
                self.faces.append((cx, cy, track_id))

                # CHANGED: Draw ID text
                cv2.putText(cv_image, f"ID: {track_id}", (int(bbox[0]), int(bbox[1])-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, self.detection_color, 2)

            cv2.imshow("image", cv_image)
            key = cv2.waitKey(1)
            if key==27:
                print("exiting")
                exit()
            
        except CvBridgeError as e:
            print(e)

    def pointcloud_callback(self, data):

        # get point cloud attributes
        height = data.height
        width = data.width
        point_step = data.point_step
        row_step = data.row_step        

        # CHANGED: Iterate with face ID
        for x,y,face_id in self.faces:

            # get 3-channel representation of the point cloud in numpy format
            a = pc2.read_points_numpy(data, field_names= ("x", "y", "z"))
            a = a.reshape((height,width,3))

            # read center coordinates
            d = a[y,x,:]

            # create marker
            marker = Marker()

            marker.header.frame_id = "/base_link"
            marker.header.stamp = data.header.stamp

            marker.type = 2
            marker.id = face_id  # CHANGED: Use actual face ID

            # Set the scale of the marker
            scale = 0.1
            marker.scale.x = scale
            marker.scale.y = scale
            marker.scale.z = scale

            # Set the color
            marker.color.r = 1.0
            marker.color.g = 1.0
            marker.color.b = 1.0
            marker.color.a = 1.0

            # Set the pose of the marker
            marker.pose.position.x = float(d[0])
            marker.pose.position.y = float(d[1])
            marker.pose.position.z = float(d[2])

            self.marker_pub.publish(marker)

            face_coords_3d = (float(d[0]), float(d[1]), float(d[2]))

            self.get_logger().info(f"Face 3D coordinates: {face_coords_3d}")
            self.get_logger().info(f"Robot position: x={self.robot_position[0]:.2f}, y={self.robot_position[1]:.2f}, Yaw: {self.robot_yaw:.2f}")
            self.save_dictionary_to_file(face_id, self.robot_position, face_coords_3d)  # CHANGED: Use actual ID


def main():
    print('Face detection node starting.')

    rclpy.init(args=None)
    node = detect_faces()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()